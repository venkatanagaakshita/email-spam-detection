{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPSfLreeEKWGfktXaKAFWNb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatanagaakshita/email-spam-detection/blob/main/Spam_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ8m1cBSmPdh"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import email\n",
        "from sklearn.model_selection import train_test_split\n",
        " "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c1nMnDHqTgT",
        "outputId": "3d8de66e-28db-4095-eb0b-d07f34c46e2a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhJzYRNpnw67"
      },
      "source": [
        "path = '/content/gdrive/My Drive/data/'"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30Gi5sZ7qkwc"
      },
      "source": [
        "easy_ham_paths = glob.glob(path+'easy_ham/*')\n",
        "spam_paths = glob.glob(path+'spam/*')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvCi2uogrCxT",
        "outputId": "95cb768d-e8b6-4f9d-b9f9-8030710d6765"
      },
      "source": [
        "ham_sample = np.array([train_test_split(easy_ham_paths, test_size = 0.3)])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_SpROuFuTVS"
      },
      "source": [
        "ham_train = np.array([])\n",
        "ham_test = np.array([])\n",
        "for i in ham_sample:\n",
        "    ham_train = np.concatenate((ham_train,i[0]),axis=0)\n",
        "    ham_test = np.concatenate((ham_test,i[1]),axis=0)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBdub0VVuXPS",
        "outputId": "69219688-09b5-414e-b23e-2da853982cc8"
      },
      "source": [
        "spam_sample = np.array([train_test_split(spam_paths, test_size = 0.3)])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI9s_tNNukvK"
      },
      "source": [
        "spam_train = np.array([])\n",
        "spam_test = np.array([])\n",
        "for i in spam_sample:\n",
        "    spam_train = np.concatenate((spam_train,i[0]),axis=0)\n",
        "    spam_test = np.concatenate((spam_test,i[1]),axis=0)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3s1D6wtup4v"
      },
      "source": [
        "ham_train_label = [0]*ham_train.shape[0]\n",
        "spam_train_label = [1]*spam_train.shape[0]\n",
        "x_train = np.concatenate((ham_train,spam_train))\n",
        "y_train = np.concatenate((ham_train_label,spam_train_label))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_UpZISCurgn"
      },
      "source": [
        "ham_test_label = [0]*ham_test.shape[0]\n",
        "spam_test_label = [1]*spam_test.shape[0]\n",
        "x_test = np.concatenate((ham_test,spam_test))\n",
        "y_test = np.concatenate((ham_test_label,spam_test_label))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbddw-fbuv-4"
      },
      "source": [
        "train_shuffle_index = np.random.permutation(np.arange(0,x_train.shape[0]))\n",
        "test_shuffle_index = np.random.permutation(np.arange(0,x_test.shape[0]))\n",
        "x_train = x_train[train_shuffle_index]\n",
        "y_train = y_train[train_shuffle_index]\n",
        "x_test = x_test[test_shuffle_index]\n",
        "y_test = y_test[test_shuffle_index]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMLsqMqDu-VV"
      },
      "source": [
        "def rem_null_data(datas,labels):\n",
        "    not_null_idx = [i for i,o in enumerate(datas) if o is not None]\n",
        "    return np.array(datas)[not_null_idx],np.array(labels)[not_null_idx]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWgEZmnivBMb"
      },
      "source": [
        "x_train,y_train = rem_null_data(x_train,y_train)\n",
        "x_test,y_test = rem_null_data(x_test,y_test)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b-EXQTLviE3"
      },
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_Z-zsI7viK7"
      },
      "source": [
        "def rem_newline(word):\n",
        "    return word.replace('\\n','')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzg4m-xAviRN"
      },
      "source": [
        "def rem_num_in_data(word):\n",
        "    result = re.sub(r'\\d+', '', word)\n",
        "    return result"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUYvxkOGvvJA"
      },
      "source": [
        "def convert_lower(word):\n",
        "    result = word.lower()\n",
        "    return result"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiQu9m-OwGQW"
      },
      "source": [
        "def rem_punc_in_data(word):\n",
        "    result = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
        "    return result"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s863kFPxwLsZ"
      },
      "source": [
        "def preprocessing(sentence):\n",
        "    cleaning_utils = [\n",
        "                      rem_newline,\n",
        "                      convert_lower,\n",
        "                      rem_num_in_data,\n",
        "                      rem_punc_in_data]\n",
        "    for i in cleaning_utils:\n",
        "        sentence = i(sentence)\n",
        "    return sentence"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LwyjyHAwXfX"
      },
      "source": [
        "x_train = [preprocessing(i) for i in x_train]\n",
        "x_test = [preprocessing(i) for i in x_test]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "819UWmjkwXnT"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
        "from nltk.stem import PorterStemmer\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4v8x1VywXvS"
      },
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13H-SzE3w5sc",
        "outputId": "1f3509e7-f5cd-4191-fdcc-bcaaa837c393"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "x_train = [word_tokenize(i) for i in x_train]\n",
        "x_test = [word_tokenize(i) for i in x_test]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcQIT-k1w5vt"
      },
      "source": [
        "def rem_stopwords(words):\n",
        "    result = [i for i in words if i not in ENGLISH_STOP_WORDS]\n",
        "    return result"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzO5qXuUw5y0"
      },
      "source": [
        "def data_stem(words):\n",
        "    return [stemmer.stem(i) for i in words]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sumORIMw514"
      },
      "source": [
        "def clean_token(words):\n",
        "    cleaning_utils = [rem_stopwords,data_stem]\n",
        "    for i in cleaning_utils:\n",
        "        words = i(words)\n",
        "    return words"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4rvuoxDxdlf"
      },
      "source": [
        "x_train = [clean_token(i) for i in x_train]\n",
        "x_test = [clean_token(i) for i in x_test]"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30Fz5Bn-xdpZ"
      },
      "source": [
        "x_train = [\" \".join(i) for i in x_train]\n",
        "x_test = [\" \".join(i) for i in x_test]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mI2tPuYrJ5x"
      },
      "source": [
        "x_train = [i.split(\" \") for i in x_train]\n",
        "x_test = [i.split(\" \") for i in x_test]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwoOjYD0rhNe"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j8i0t5frheK",
        "outputId": "111a50e8-7c70-40fe-c279-6a67dbd150ec"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "raw_sentences = [' '.join(i) for i in x_train]\n",
        "vectorizer.fit(raw_sentences)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
              "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJvVzagcrhjG"
      },
      "source": [
        "def convert_to_feature(raw_tokenize_data):\n",
        "    raw_sentences = [' '.join(i) for i in raw_tokenize_data]\n",
        "    return vectorizer.transform(raw_sentences)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2EGJziprhng"
      },
      "source": [
        "x_train_features = convert_to_feature(x_train)\n",
        "x_test_features = convert_to_feature(x_test)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MuUDp3AtQi9"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrJEJ552tQnM",
        "outputId": "372491d3-29a6-4eec-c155-080aae934fba"
      },
      "source": [
        "dtModel = DecisionTreeClassifier(class_weight=None,\n",
        " max_features = 50, min_impurity_split=1e-07, min_samples_leaf=1,\n",
        " min_samples_split=2, max_depth = 100, min_weight_fraction_leaf=0.0, random_state=18, splitter='best')\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "dtModel = dtModel.fit(x_train_features.toarray(),y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = dtModel.predict(x_test_features.toarray())"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py:301: FutureWarning: The min_impurity_split parameter is deprecated. Its default value will change from 1e-7 to 0 in version 0.23, and it will be removed in 0.25. Use the min_impurity_decrease parameter instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-euhJZQtQri",
        "outputId": "99d74b4b-5fbb-438f-c76c-da85517bfb52"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8375136314067612\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}